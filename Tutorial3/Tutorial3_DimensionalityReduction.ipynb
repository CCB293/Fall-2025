{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/audreywang1997/CMPBIO293_Fall2024/blob/main/Tutorial2_DimensionalityReduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEyN62LJQOQ7"
   },
   "source": [
    "#Tutorial 2: PCA, t-SNE, and UMAP\n",
    "\n",
    "This tutorial is adapted from multiple resources:\n",
    "\n",
    "*   Justin Bois and Caltech's [BE/Bi 103](https://https://bebi103a.github.io/) a course staff\n",
    "*   2016 Heidi Klumpe and Manuel Razo\n",
    "*   (c) 2016 Heidi Klumpe. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained therein is licensed under an [MIT license](https://opensource.org/licenses/MIT). Some code from the scikit-learn tutorial are [BSD licensed](https://opensource.org/licenses/BSD-3-Clause).\n",
    "*   Berkeley's CS189/289A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7sk17WnWET9"
   },
   "source": [
    "###Download libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18365,
     "status": "ok",
     "timestamp": 1760538716475,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "u9cBRxWWt8Lj",
    "outputId": "233f0a62-5191-4d06-c141-ecdd7dc3a6ff"
   },
   "outputs": [],
   "source": [
    "pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40677,
     "status": "ok",
     "timestamp": 1760538757172,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "j6cm5IkbQOQ9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# Packages to perform dimensionality reduction\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import umap\n",
    "from umap import UMAP\n",
    "\n",
    "# Packages for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "from matplotlib import offsetbox\n",
    "import seaborn as sns\n",
    "rc={'lines.linewidth': 2, 'axes.labelsize': 14, 'axes.titlesize': 14}\n",
    "sns.set(rc=rc)\n",
    "\n",
    "# Make Matplotlib plots appear inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRFjTqnxW7J2"
   },
   "source": [
    "###PCA in the biological sciences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJT7G6HXWXKB"
   },
   "source": [
    "#### The famous iris data set\n",
    "\n",
    "We will use one of the most famous datasets available online. This dataset, collected by Edgar Anderson, contains the petal and sepal length and width in three different species of Iris (*Iris setosa*, *Iris virginica* and *Iris versicolor*).\n",
    "\n",
    "This data set is popular enough to have its own [Wikipedia entry](https://en.wikipedia.org/wiki/Iris_flower_data_set), and you can import it with [seaborn](http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html?highlight=iris), [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html), or even pandas using\n",
    "\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "    df = pd.read_csv(filepath_or_buffer=url, header=None, sep=',')\n",
    "\n",
    "For this tutorial, we will import it using `scikit-learn` and transform it into a tidy data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1760538773525,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "hpZOTeV6WXKB",
    "outputId": "eb029eb6-b91c-4689-db72-95ea2fcc4c85"
   },
   "outputs": [],
   "source": [
    "# Import the Iris dataset and convert it into a Pandas DataFrame\n",
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "# Uncomment if you want to print the dataset description\n",
    "# print(iris.DESCR)\n",
    "\n",
    "# Make a DataFrame with a species column\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris['species'] = iris.target_names[iris.target]\n",
    "\n",
    "# Take a look at df_iris\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l592b2xMWXKB"
   },
   "source": [
    "We can plot pairwise comparisons using Seaborn's `pairplot()` function to see if there are striking correlations between any two features of the iris data set. If any two features are highly correlated, we may assume we can summarize those two features with a single axis (i.e. \"new\" feature) that includes both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15906,
     "status": "ok",
     "timestamp": 1760538791637,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "e3kLMzHCWXKC",
    "outputId": "04585d5a-4f9c-4e31-cb85-051fcaae76d6"
   },
   "outputs": [],
   "source": [
    "# Plot pairwise comparison to explore the data\n",
    "_ = sns.pairplot(df_iris, hue='species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCV7g_ajWXKC"
   },
   "source": [
    "Right away from this plot we can notice that *versicolor* and *virginica* are more similar to each other than to *setosa*.  There is also a strong correlation between *petal length* and *petal width*. We can use this to explain the concept behind PCA. So, let's focus on these two parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1760538792061,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "Wan176z2WXKC",
    "outputId": "1d9ea030-fc12-4ce4-f52b-57163b0aed4e"
   },
   "outputs": [],
   "source": [
    "# Compute the mean\n",
    "m = np.array([df_iris['petal length (cm)'].mean(),\n",
    "              df_iris['petal width (cm)'].mean()])\n",
    "\n",
    "# Plot petal length vs petal width only\n",
    "for key, group in df_iris.groupby(['species']):\n",
    "    plt.plot(group['petal length (cm)'], group['petal width (cm)'],\n",
    "               label=key, marker='.', linestyle='none')\n",
    "\n",
    "# Add the mean value to the plot\n",
    "plt.plot(m[0], m[1], marker='*', color='black', markersize=15,\n",
    "         linestyle='none', label='mean')\n",
    "\n",
    "plt.legend(loc=0)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XN-moa7VWXKC"
   },
   "source": [
    "Now, we do PCA by hand. Our goal will be to reduce our 2-D data to 1-D. Note that by taking the mean, we already reduced it 0-D in a sense.\n",
    "\n",
    "**1) Standardize the data.**\n",
    "PCA looks for the directions of greatest variation. If one of our measurements is inherently more variable, PCA will pay too much attention to it. A common standardization trick is to subtract the mean and divide by the standard deviation. Then, each measurement represents \"standard deviations from the mean\" instead of centimeters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760538796723,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "kWg6lIxRWXKC",
    "outputId": "a3c6fbde-585f-4841-cb3e-2ce5235ec7d8"
   },
   "outputs": [],
   "source": [
    "# Substract the mean from the measurements.\n",
    "df_centered = df_iris.loc[:, ['petal length (cm)', 'petal width (cm)']]\n",
    "for col in df_centered.columns:\n",
    "    df_centered[col]  = (df_centered[col] - df_centered[col].mean()) / df_centered[col].std()\n",
    "\n",
    "# Take a look\n",
    "df_centered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XJKLxPCWXKC"
   },
   "source": [
    "**2) Compute the covariance matrix and use eigenvalue decomposition to obtain the eigenvectors and eigenvalues.**\n",
    "\n",
    "We won't cover the math behind this procedure. However, [it can be shown](https://en.wikipedia.org/wiki/Principal_component_analysis#First_component) that the principal component directions are given by the eigenvectors of the matrix, and the magnitudes of the components are given by the eigenvalues.\n",
    "\n",
    "Most of the available algorithms to do PCA use [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) instead for computational efficiency. But regardless of the algorithm the objective is still the same: compute the eigenvectors and eigenvalues from the covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1760538801181,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "3fvoz-NRWXKC",
    "outputId": "9bd3d53c-c258-4e8e-83df-c5ff67d52cde"
   },
   "outputs": [],
   "source": [
    "cov_mat = np.cov(df_centered.transpose())\n",
    "print('Covariance matrix \\n', cov_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhZEmEaHWXKC"
   },
   "source": [
    "Next, we'll compute the eigensystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1760538803015,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "ZlYhzOCNWXKC",
    "outputId": "dc8bbd63-323d-4325-bd2b-75e3bd7b1db1"
   },
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "# sort from largest to smallest\n",
    "idx = np.argsort(eig_vals)[::-1]\n",
    "eig_vals = eig_vals[idx]\n",
    "eig_vecs = eig_vecs[:, idx]\n",
    "print('Eigenvectors\\n', eig_vecs)\n",
    "print('\\nEigenvalues\\n', eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWnOds2HWXKC"
   },
   "source": [
    "We can plot the eigenvectors on top of our data to get a sense of how these principal components can capture the variation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1760538805052,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "5YhS5TaJWXKC",
    "outputId": "03e2af1b-6b11-47d1-d62f-039f2763991d"
   },
   "outputs": [],
   "source": [
    "# Plot Petal length vs petal width only\n",
    "for key, group in df_iris.groupby(['species']):\n",
    "    plt.plot(group['petal length (cm)'], group['petal width (cm)'],\n",
    "               label=key, marker='o', linestyle='none')\n",
    "\n",
    "# Add the mean value to the plot\n",
    "plt.plot(m[0], m[1], marker='*', color='black', markersize=15)\n",
    "\n",
    "# Add arrows showing the eigenvectors\n",
    "plt.quiver([m[0]]*2, [m[1]]*2, eig_vecs[:,1], eig_vecs[:,0], zorder=11,\n",
    "           width=0.01, scale=3)\n",
    "\n",
    "# Tidy up plot\n",
    "plt.legend(loc=0, fontsize=15)\n",
    "plt.margins(0.02)\n",
    "plt.xlabel('petal length (cm)')\n",
    "plt.ylabel('petal width (cm)')\n",
    "plt.title('Iris data with principal components');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsCchTEXWXKC"
   },
   "source": [
    "**3) Select the $k$ largest eigenvalues and their associated eigenvectors.**\n",
    "\n",
    "As [Sebastian Raschka](http://sebastianraschka.com/index.html) points out in his explanation of PCA:\n",
    "\n",
    ">*The eigenvectors (principal components) determine the directions of the new feature space, and the eigenvalues determine their magnitude. In other words, the eigenvalues explain the variance of the data along the new feature axes*.\n",
    "\n",
    "We chose this pair of measurements originally because there was a clear correlation between them. This is indeed confirmed by the relative magnitudes of the *eigenvalues* where one of them is two orders of magnitude larger than the other. Clearly, describing this data with two axes, rather than one, does not add much additional information. Also, we know which eigenvector to take: the one with the largest eigenvalue.\n",
    "\n",
    "[Lior Pachter's great blog post on PCA](https://liorpachter.wordpress.com/2014/05/26/what-is-principal-component-analysis/), which we will discuss more later, explains this 2-D to 1-D case by thinking of the projection as a triangle. Let's say we want to project a single data point onto the first principal component. The centroid (fixed) and the data point (also fixed) form a triangle with the the transformed data point (an orthogonal projection onto the first principal component).\n",
    "\n",
    "The hypotenuse of the triangle (the distance from the centroid to the data point) is fixed, so the other two sides must change together (by the Pythagorean Theorem). The first principal component has a minimal orthogonal distance to all the data points. So the side of the triangle between the data point and the transformed data point is as small as possible. This means the distance between the centroid and the transformed point is as large as possible (though still smaller than the original distance between the data point and the centroid)!\n",
    "\n",
    "This is what we mean when we say that using PCA to project the data into fewer dimensions maximizes the sample variation (i.e. their distances from each other after they've been transformed), despite some information being lost.\n",
    "\n",
    "Luckily, we can quantify about how much information is lost. As the eigenvalues are a relative measure of the data variance along the associated eigenvector (i.e. the \"new feature axis\"), we can use them to quantify how much of the variance is explained by our $k$ dimensions, which could be a useful way to decide what $k$ should even be in the first place. In this case, we want to know how much of the 2-D spread is described by our 1-D simplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1760538808823,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "IWW1cXQTWXKC",
    "outputId": "1c79155d-fc5f-424d-d1a2-641d746600bb"
   },
   "outputs": [],
   "source": [
    "# Compute how much variance is explained by each principal component\n",
    "print(\"\"\"\n",
    "PCA 1: {0:.2f}% of the variance\n",
    "PCA 2:  {1:.2f}% of the variance\n",
    "\"\"\".format(*tuple(eig_vals / np.sum(eig_vals) * 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyrlUvZKWXKC"
   },
   "source": [
    "**4) Transform the data into a $k$ dimensional subspace using those $k$ eigenvectors.**\n",
    "\n",
    "To actually project our data into this new dimension, we have to multiply our data by the so-called projection matrix, which is the concatenation the top $k$ eigenvectors. Each of these eigenvectors represents a direction of high variation in the dataset. Multiplying our samples by these directions scores how far in each direction each sample lands.\n",
    "\n",
    "Since in this simple example we are projecting into a 1D space, we just have to matrix multiply our data by the eigenvector with the largest corresponding eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1760538810708,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "VcYPWPrxWXKC",
    "outputId": "79774774-f425-4007-c8c3-f2d6d4c8a24b"
   },
   "outputs": [],
   "source": [
    "# Project data to our 1D space\n",
    "df_1D = pd.DataFrame(np.dot(df_iris.loc[:,['petal length (cm)',\n",
    "                                           'petal width (cm)']], eig_vecs[:,0]),\n",
    "                     columns=['projection'])\n",
    "\n",
    "# Add back the species column\n",
    "df_1D['species'] = df_iris['species']\n",
    "df_1D.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynK84mIGWXKC"
   },
   "source": [
    "Now we can plot our data in 1D only while maintaining ≈98% percent of the variability in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1760538813041,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "tdR3covqWXKD",
    "outputId": "e2fba264-939a-4f02-c508-7667a1f24a4b"
   },
   "outputs": [],
   "source": [
    "for key, group in df_1D.groupby(['species']):\n",
    "    plt.plot(group['projection'], np.zeros_like(group['projection']), alpha=0.4,\n",
    "             label=key, marker='o', linestyle='none')\n",
    "\n",
    "plt.margins(0.05)\n",
    "plt.xlabel('PCA 1')\n",
    "plt.legend(np.array(['setosa', 'versicolor','virginica']))\n",
    "plt.title('Projection of petal length v. petal width onto one axis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpL6ZlK6WXKD"
   },
   "source": [
    "Exciting! We were able to project 2-D data onto a 1-D axis, and still have a sense of how these various iris species differ. Note that while the new dimension has numerical values, its interpretation is a bit fuzzy. It's in fact a weighted combination of *petal length* and *petal width*, but this doesn't necessarily tell us anything new about biology, except that these two variables are related and potentially very different in various iris species. However, we might have known this by computing their covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuZzafkLWXKD"
   },
   "source": [
    "### `Scikit-learn` shortcut for PCA\n",
    "\n",
    "Now that we explored step-by-step how to do PCA, we can use `scikit-learn` to do it in a single line.  For this, we will take all 4 dimensions of the original dataset (petal length, petal width, sepal length, and sepal width) and explore how much variability is explained by each of the resulting principal components.\n",
    "\n",
    "`Scikit-learn` utilizes Python's object orientation. An object is first instantiated by the user, and has various variables (i.e. class and instance variables) and methods (i.e. functions) you can access (more definitions [here](https://www.tutorialspoint.com/python/python_classes_objects.htm)). We first instantiate a `sklearn.decomposition.PCA` object, and the use the `fit()` method to get PCA on our data.  The attributes of the `PCA` instance that end in underscores are the computed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1760538815959,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "uQdl1uKmWXKD",
    "outputId": "bd609bbe-45b3-4bd0-ac8e-e7ec0e105d15"
   },
   "outputs": [],
   "source": [
    "# Instantiate the PCA object\n",
    "sklearn_pca = sklearn.decomposition.PCA()\n",
    "\n",
    "## transform the data\n",
    "scaled_data = (df_iris[iris.feature_names] - df_iris[iris.feature_names].mean()) / df_iris[iris.feature_names].std()\n",
    "\n",
    "# Pass the data to the fit method\n",
    "sklearn_pca.fit(scaled_data)\n",
    "#sklearn_pca.fit(df_iris[iris.feature_names])\n",
    "\n",
    "# Print the variance explained\n",
    "print('Variance percent explained\\n', sklearn_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4Aa-h_ZWXKD"
   },
   "source": [
    "We can see that the first component captures 73% of the variability in the data! We can now easily project our 4-D dataset into any $k$ dimensional space we would like. Since we've already seen a 0-D and 1-D reduction, let's look at the data in 2-D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1760538818664,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "z9WUCbXWWXKD",
    "outputId": "f37f3f35-cc8b-4f92-f582-14e2b3bd000d"
   },
   "outputs": [],
   "source": [
    "# Perform the PCA again retaining only the top 2 components\n",
    "sklearn_pca = sklearn.decomposition.PCA(n_components=2)\n",
    "sklearn_pca.fit(scaled_data)\n",
    "\n",
    "# Project the data into this 2D space and convert it back to a tidy dataframe\n",
    "df_2D = pd.DataFrame(sklearn_pca.transform(scaled_data),\n",
    "                     columns=['PCA1', 'PCA2'])\n",
    "\n",
    "# Create a column for species name\n",
    "df_2D['species'] = df_iris['species']\n",
    "\n",
    "# Look at the result\n",
    "df_2D.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBhXmNMxWXKD"
   },
   "source": [
    "Now we can plot our original 4-D data onto a 2-D space that retains nearly 96% of the variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1760538820923,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "wVia3W-vWXKD",
    "outputId": "770e0a01-478b-4230-8b76-4a37194106df"
   },
   "outputs": [],
   "source": [
    "for key, group in df_2D.groupby(['species']):\n",
    "    plt.plot(group.PCA1, group.PCA2, 'o', alpha=0.7, label=key)\n",
    "\n",
    "# Tidy up plot\n",
    "plt.legend(loc=0)\n",
    "plt.margins(0.05)\n",
    "plt.xlabel('PCA 1 (72.9%)')\n",
    "plt.ylabel('PCA 2 (22.9%)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iL8ToVijQOQ-"
   },
   "source": [
    "### Non linear methods\n",
    "\n",
    "Below is an example adapted from the `scikit-learn` documentation on [manifold learning](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py), written by Fabian Pedegrosa, Olivier Grisel, Mathieu Blondel, and Gael Varoquaux. We will compare linear and non-linear dimensionality reduction to create clusters of hand-drawn digits. We can import a dataset of these hand-drawn numbers from the `sklearn` module.\n",
    "\n",
    "We will use t-SNE and UMAP. Unlike PCA, these do not preserve the global structure of the dataset. Instead, they try to find a low dimensional space where the local area around each point matches the local area in the high dimensional space.\n",
    "\n",
    "\n",
    "MNIST is a database. The acronym stands for “Modified National Institute of Standards and Technology.” The MNIST database contains handwritten digits (0 through 9), and can provide a baseline for testing image processing systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1760538823528,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "JbK86N2-qJK2",
    "outputId": "ee591b85-1897-4f2d-d18a-1ecfd2cf5e8a"
   },
   "outputs": [],
   "source": [
    "# Load the data from sklearn\n",
    "digits = sklearn.datasets.load_digits(n_class=10)\n",
    "\n",
    "# Store the data and targets\n",
    "digit_images = digits.data\n",
    "digit_classes = digits.target\n",
    "\n",
    "# The data are rows of pixel values, and each pixel value is a feature (64 pixels in an 8x8 image).\n",
    "n_samples, n_features = digit_images.shape\n",
    "\n",
    "# Take a look at the data\n",
    "n_img_per_row = 20\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10*i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10*j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = digit_images[i * n_img_per_row + j].reshape((8,8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('A selection from the 64-dimensional digits dataset');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raAp7f6TlJWE"
   },
   "source": [
    "Data Set Characteristics:\n",
    "\n",
    "    :Number of Instances: 5620\n",
    "    :Number of Attributes: 64\n",
    "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
    "    :Missing Attribute Values: None\n",
    "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
    "    :Date: July; 1998\n",
    "\n",
    "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
    "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cav3hn4-QOQ-"
   },
   "source": [
    "In the [tutorial](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py), they define a function to plot a picture of each number, rather than merely a point. This will be useful for determining the success of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760538825790,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "cipn7HunQOQ-"
   },
   "outputs": [],
   "source": [
    "def plot_embedding(embed, title=None, show_classes=True, show_examples=True):\n",
    "    # Determine range of values of embedded points\n",
    "    x_min, x_max = np.min(embed, 0), np.max(embed, 0)\n",
    "    # Scale all points between 0 and 1\n",
    "    scaled_embed = (embed - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Instantiate figure\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    if show_classes:\n",
    "        # Color each number differently (shows how we expect data to cluster)\n",
    "        for i in range(scaled_embed.shape[0]):\n",
    "            plt.plot(scaled_embed[i,0], scaled_embed[i,1], '.',\n",
    "                     color = plt.cm.Set1(digit_classes[i]/10))\n",
    "    else:\n",
    "        plt.plot(scaled_embed[:,0], scaled_embed[:,1], '.k')\n",
    "\n",
    "    if show_examples:\n",
    "        if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "            # Only print thumbnail with matplotlib > 1.0;\n",
    "            # initialize shown_images array\n",
    "            shown_images = np.array([[1, 1]])\n",
    "\n",
    "            # Iterate through the number of digits we imported\n",
    "            for i in range(digits.data.shape[0]):\n",
    "                dist = np.sum((scaled_embed[i] - shown_images) **2, 1)\n",
    "                # Don't put thumbnails too close together\n",
    "                if np.min(dist) < 4e-3:\n",
    "                    continue\n",
    "                # Concatenate the  locations of the images to be plotted\n",
    "                shown_images = np.r_[shown_images, [scaled_embed[i]]]\n",
    "                # Define the grayscale image of the number\n",
    "                imagebox = offsetbox.AnnotationBbox(\n",
    "                    offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                    scaled_embed[i])\n",
    "                ax.add_artist(imagebox)\n",
    "\n",
    "    # Remove x and y ticks\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cEvdzXWQOQ-"
   },
   "source": [
    "Now, we will use PCA (our linear approach) and t-SNE and UMAP (our non-linear approaches) to reduce this 64-dimensional dataset to 2 dimensions. (We will discuss the t-SNE syntax in more detail later on.) Keep in mind that each \"dimension\" is the grayscale value of each pixel in the image of the hand-drawn digit. We want to see if the structure of the data (i.e. what we know about which images are 0s, 1s, 2s, etc.) is visible in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52340,
     "status": "ok",
     "timestamp": 1760538880407,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "_mq1EinJQOQ-",
    "outputId": "3f596e1b-3880-49f7-d65e-17d7ef2098a5"
   },
   "outputs": [],
   "source": [
    "# Time the PCA computation\n",
    "t0 = time()  # Use time.time() to get the correct timing\n",
    "# Use PCA for dimensionality reduction\n",
    "digit_pca = sklearn.decomposition.PCA(n_components=2)\n",
    "# Transform the data\n",
    "embed_pca = digit_pca.fit_transform(digit_images)\n",
    "# Store the time\n",
    "t_pca = time() - t0\n",
    "# Print time\n",
    "print('PCA took %.3fs.' % t_pca)\n",
    "\n",
    "# Time the t-SNE computation\n",
    "t0 = time()\n",
    "# Find the optimal low-dimensional representation with t-SNE\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "embed_tsne = tsne.fit_transform(digit_images)\n",
    "# Store the time\n",
    "t_tsne = time() - t0\n",
    "# Print time\n",
    "print('t-SNE took %.3fs.' % t_tsne)\n",
    "\n",
    "# Time the UMAP computation\n",
    "t0 = time()\n",
    "\n",
    "# Find the optimal low-dimensional representation with UMAP\n",
    "umap = umap.UMAP()\n",
    "embed_umap = umap.fit_transform(digit_images)  # Use the reducer object here\n",
    "\n",
    "# Store the time\n",
    "t_umap = time() - t0\n",
    "\n",
    "# Print time\n",
    "print('UMAP took %.3fs.' % t_umap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UefLT4TyQOQ-"
   },
   "source": [
    "Wow. We can already see that t-SNE takes almost 100 times longer. We can compare the results by plotting the resulting low-dimensional spaces (also called the embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1760538880890,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "Rq57fPZ4QOQ_",
    "outputId": "4ec56435-85af-488c-9f28-6462a45ad1c7"
   },
   "outputs": [],
   "source": [
    "plot_embedding(embed_pca, \"PCA result\", show_classes=False, show_examples=False)\n",
    "plot_embedding(embed_tsne, \"t-SNE result\", show_classes=False, show_examples=False)\n",
    "plot_embedding(embed_umap, \"UMAP result\", show_classes=False, show_examples=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWD6oiEIQOQ_"
   },
   "source": [
    "Here, we see PCA fails to give us what we were after, which is a clean separation of digits into clusters.\n",
    "\n",
    "In contrast, t-SNE and UMAP show distinct groups. There are roughly 7-8 clusters, depending on how you count. This is intriguing as we know there are 6 hand-drawn digits, ranging from 0 to 5.\n",
    "\n",
    "To get a better idea of what these maps are trying to communicate, let's color each point by the digit it represents, and overlay them with a few images of those hand-drawn digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 18502,
     "status": "ok",
     "timestamp": 1760538899394,
     "user": {
      "displayName": "Mark George Young",
      "userId": "13705858165710521600"
     },
     "user_tz": 420
    },
    "id": "5-UfgxQ7QOQ_",
    "outputId": "36d0dbfa-1724-4867-de8b-aec36bbe048c"
   },
   "outputs": [],
   "source": [
    "plot_embedding(embed_pca, \"PCA result\")\n",
    "plot_embedding(embed_tsne, \"t-SNE result\")\n",
    "plot_embedding(embed_umap, \"UMAP result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "pivS37YNQOQ_"
   },
   "source": [
    "We see that PCA did actually separate the different numbers. However, without labels, this was impossible to see.\n",
    "\n",
    "t-SNE and UMAP, on the other hand, separate the numbers into discrete clusters quite well, providing more information about the local structure of the data.\n",
    "\n",
    "So why does PCA fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8y8DK74bQOQ_"
   },
   "source": [
    "### Directions of high variance, which PCA preserves, is not the same thing as local similarity\n",
    "\n",
    "On many datasets, like the iris dataset, directions of high variance correspond to useful features for discerning between irisis.\n",
    "\n",
    "On others, like MNIST, they often correspond to non-usefull stuff like stroke thickness, slant, or lighting.\n",
    "\n",
    "Changing the objective function to similarity between pairs of digits can really improve clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ANbUB7vQORB"
   },
   "source": [
    "### Summary\n",
    "\n",
    "* Visualizing a high-dimensional biological dataset in 2D is useful for understanding its intrinsic structure.\n",
    "* Linear dimensionality reduction sometimes struggles to find discrete clusters\n",
    "* This is because directions of greatest global variance do not always correspond to local similarity\n",
    "* t-SNE and UMAP take two separate approaches to capturing local structure of a dataset\n",
    "* t-SNE finds a low dimensional space where the distances between pairs nearest neighbor points are as close as possible to the high dimensional space\n",
    "* UMAP matches local neighborhoods between the low and high dimensional spaces\n",
    "* Both have various hyperparameters that drastically influence output (such as n neighbors)\n",
    "* Neither preserves global distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PeifcraEQORI"
   },
   "source": [
    "### References\n",
    "Informal introduction to t-SNE, by creator. [Google TechTalk](https://www.youtube.com/watch?v=RJVL80Gg3lA).\n",
    "\n",
    "Formal introduction to t-SNE: L.J.P. van der Maaten and G.E. Hinton. Visualizing High-Dimensional Data Using t-SNE. _Journal of Machine Learning Research_ 9(Nov):2579-2605, 2008.\n",
    "\n",
    "Using the Barnes-Hut approximation: L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms. _Journal of Machine Learning Research_ 15(Oct):3221-3245, 2014.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
