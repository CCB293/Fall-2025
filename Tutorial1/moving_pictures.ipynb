{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5d8219d",
   "metadata": {},
   "source": [
    "# Tutorial 1: \"Moving Pictures\"\n",
    "\n",
    "For the in class portion of our qiime2 primer, we'll be working through the \"Moving Pictures\" tutorial published on the qiime2 docs (https://amplicon-docs.qiime2.org/en/latest/tutorials/moving-pictures.html). \n",
    "\n",
    "We'll be using a small dataset of samples collected across from two individuals who took antibiotics. Each individual was sampled at four body sites, four times, over six months, beginning with the antibiotic exposure. \n",
    "\n",
    "We're going to practice processing raw read data into ASVs, creating a phylogeny, running diversity analysis, and testing for differential abundance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeea512",
   "metadata": {},
   "source": [
    "## 1) Load the dataset into QIIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd57d6",
   "metadata": {},
   "source": [
    "**Step 1: load sample metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe77519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiime2 import Metadata\n",
    "import requests\n",
    "## download the metadata file from the online source\n",
    "url = 'https://moving-pictures-tutorial.readthedocs.io/en/latest/data/moving-pictures/sample-metadata.tsv'\n",
    "fn = 'sample-metadata.tsv'\n",
    "r= requests.get(url)\n",
    "with open(fn, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "### remove dashes from column names \n",
    "import pandas as pd\n",
    "pd.read_csv('sample-metadata.tsv',sep='\\t',index_col=0).rename(columns = {'reported-antibiotic-usage':\\\n",
    "     'reported_antibiotic_usage', 'days-since-experiment-start': 'days_since_experiment_start'}).to_csv('sample-metadata.tsv', sep = '\\t')\n",
    "## load into qiime2\n",
    "sample_metadata_md = Metadata.load(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd4f6a1",
   "metadata": {},
   "source": [
    "Create an interactive table!\n",
    "- you can view this at https://view.qiime2.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.metadata.actions as metadata_actions\n",
    "\n",
    "sample_metadata_viz, = metadata_actions.tabulate(\n",
    "    input=sample_metadata_md,\n",
    ")\n",
    "sample_metadata_viz.save('sample-metadata.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c566e",
   "metadata": {},
   "source": [
    "Alternatively, just export to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_pandas= sample_metadata_md.to_dataframe()\n",
    "metadata_pandas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e00f8",
   "metadata": {},
   "source": [
    "**Step 2: download the sequences**\n",
    "\n",
    "Our data is pretty old (2011!), so its single-end. Its also still multiplexed, so just one big file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33350fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "## again, use the requests library to download from the online source\n",
    "url = 'https://moving-pictures-tutorial.readthedocs.io/en/latest/data/moving-pictures/emp-single-end-sequences.zip'\n",
    "fn = 'emp-single-end-sequences.zip'\n",
    "r = requests.get(url)\n",
    "with open(fn, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "## extra unzipping step \n",
    "with zipfile.ZipFile(fn) as zf:\n",
    "    zf.extractall('emp-single-end-sequences')\n",
    "## load into a qiime2 data structure, the \"artifact\"\n",
    "from qiime2 import Artifact\n",
    "emp_single_end_sequences = Artifact.import_data(\n",
    "    'EMPSingleEndSequences',\n",
    "    'emp-single-end-sequences',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2910cb7",
   "metadata": {},
   "source": [
    "## 2) Demultiplex the sequences and processes reads into ASVs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10b88c",
   "metadata": {},
   "source": [
    "**Step 1: match reads to samples (demultiplexing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b26e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.demux.actions as demux_actions\n",
    "## each sample has a unique barcode sequence. pull it out of the metadata\n",
    "barcode_sequence_mdc = sample_metadata_md.get_column('barcode-sequence')\n",
    "## now feed it to qiime's demultiplexing function\n",
    "demux, demux_details = demux_actions.emp_single(\n",
    "    seqs=emp_single_end_sequences,\n",
    "    barcodes=barcode_sequence_mdc,\n",
    ")\n",
    "## summarize the demultiplexing results\n",
    "demux_viz, = demux_actions.summarize(\n",
    "    data=demux,\n",
    ")\n",
    "## save for export to qiime2 view\n",
    "demux_viz.save('demux.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c4b55d",
   "metadata": {},
   "source": [
    "**Step 2: take a look at base quality scores**\n",
    "\n",
    "Read quality is often lower at the ends. We'll want to remove lower quality bases before creating ASVs. \n",
    "\n",
    "Take a look at the file you just created (demux.qzv) at https://view.qiime2.org/. Find the position on the Interactive Quality Plot where quality scores start to get pretty low (ie < 20). \n",
    "\n",
    "I think 120 bases is a pretty good spot to trim.\n",
    "\n",
    "We'll provide our denoising tool (DADA2) with this information and it will slice off the lower quality tails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ee5f3",
   "metadata": {},
   "source": [
    "**Step 3: create ASVs (denoise)**\n",
    "\n",
    "We're using DADA2 to create our ASVs. DADA2 tries to recover the underlying, true 16S sequences, given the sequencing data and quality scores that we see. \n",
    "\n",
    "In our dataset, we have 34 samples, each with ~7,800 reads, all 120 bases long, for a total of ~32 million bases.\n",
    "\n",
    "Each base has an associated Phred, or \"Q\", score. They represent error rate as  $Q= -10\\log_{10}(P_{\\text{error}})$\n",
    "\n",
    "Therefore, even if we had really high Q-scores of 30 (1/1000 error rate), DADA2 would still look to correct 32 million/ 1000 = 32 thousand errors!\n",
    "\n",
    "In addition to correcting sequencing errors, DADA2 also seeks identify and remove chimeric sequences produced during PCR. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2139627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.dada2.actions as dada2_actions\n",
    "# input: the demultiplexed sequences, trimming parameters\n",
    "# output: a feature table (samples x ASVs), ASV sequences, and denoising stats (stuff like ASVs/sample)\n",
    "table, rep_seqs, stats = dada2_actions.denoise_single(\n",
    "    demultiplexed_seqs=demux,\n",
    "    trim_left=0,\n",
    "    trunc_len=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ffa9b",
   "metadata": {},
   "source": [
    "tabulate statistics on the denoising (and view at view.qiime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cab7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dada2_md_md = stats.view(Metadata)\n",
    "stats_viz, = metadata_actions.tabulate(\n",
    "    input=stats_dada2_md_md,\n",
    ")\n",
    "stats_viz.save('stats_viz.dada2.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f25d8d",
   "metadata": {},
   "source": [
    "... or just use pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dada2_md_md.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5488ea",
   "metadata": {},
   "source": [
    "#### *Question: How many non-chimeric reads do we recover per sample, on average?*\n",
    "\n",
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c61e2",
   "metadata": {},
   "source": [
    "## 3) Build a tree and taxonomize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06ba97",
   "metadata": {},
   "source": [
    "**Step 1: tree building**\n",
    "\n",
    "\n",
    "Bacterial 16S sequences have been used for building phylogenies since the '70s. We're going to use MAFFT to create a multiple sequence alignment and FastTree to create a tree. Qiime wraps all of this in a single command. By default, qiime uses midpoint rooting and masks highly variable positions in the MSA before tree building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68985630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.phylogeny.actions as phylogeny_actions\n",
    "\n",
    "aligned_rep_seqs, masked_aligned_rep_seqs, unrooted_tree, rooted_tree = phylogeny_actions.align_to_tree_mafft_fasttree(\n",
    "    sequences=rep_seqs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a9c528",
   "metadata": {},
   "source": [
    "**Step 2: taxonomizing**\n",
    "\n",
    "It's standard practice to use a naive bayes classifier to taxonomize 16S ASVs. Under the hood, qiime2 is just using using the scikit-learn python library. There are two main 16S databases, Silva and GreenGenes. GreenGenes is currently more up to date. Folks at qiime2 train and publish classifier weights on the qiime2 site, so all we have to do is download and run their classifier on our data. \n",
    "\n",
    "The qiime2 command will automatically provide classifications at all taxonomic levels. By default, it returns classifications with confidences (posterior probability) > 0.7. In the literature, its pretty common to use an NB classifier for kingdom to genus level classifications, and exact string matches for species and below. \n",
    "\n",
    "- *Note*: taxonomy and phylogeny are generally treated separately in 16S metagenomic workflows. This means that choice of database will not impact phylogeny-based diversity analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069aeb84",
   "metadata": {},
   "source": [
    "Download:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.qiime2.org/2021.8/common/gg-13-8-99-515-806-nb-classifier.qza'\n",
    "fn = 'gg-13-8-99-515-806-nb-classifier.qza'\n",
    "r = requests.get(url)\n",
    "with open(fn, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "gg_13_8_99_515_806_nb_classifier = Artifact.load(fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472716c3",
   "metadata": {},
   "source": [
    "Run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.feature_classifier.actions as feature_classifier_actions\n",
    "## run the classifier\n",
    "taxonomy, = feature_classifier_actions.classify_sklearn(\n",
    "    classifier=gg_13_8_99_515_806_nb_classifier,\n",
    "    reads=rep_seqs,\n",
    ")\n",
    "## export to a version that we can view\n",
    "taxonomy_as_md_md = taxonomy.view(Metadata)\n",
    "taxonomy_viz, = metadata_actions.tabulate(\n",
    "    input=taxonomy_as_md_md,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0023b",
   "metadata": {},
   "source": [
    "Taxonomies for our 770 ASVs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_as_md_md.to_dataframe().sort_values(by = 'Confidence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441fcb92",
   "metadata": {},
   "source": [
    "**Step 3: create the taxa barplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf61d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.taxa.actions as taxa_actions\n",
    "\n",
    "taxa_bar_plots_viz, = taxa_actions.barplot(\n",
    "    table=table,\n",
    "    taxonomy=taxonomy,\n",
    "    metadata=sample_metadata_md,\n",
    ")\n",
    "taxa_bar_plots_viz.save('taxa_barplot.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef74b8",
   "metadata": {},
   "source": [
    "### *Question: Load the taxa barplot. Color by level 3 taxonomy (class) and sort by body site. Which body site is characterized by high relative abundances of Clostridia?*\n",
    "\n",
    "*answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f7b3e6",
   "metadata": {},
   "source": [
    "## 4) Diversity analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b55a9",
   "metadata": {},
   "source": [
    "**Step 1: create an alpha rarefaction plot**\n",
    "\n",
    "Richness (how many ASVs we see in a sample) and other alpha diversity measures are dependent on sampling depth. This function will downsample each sample and plot alpha diversity as a function of sampling depth.\n",
    "\n",
    "Later on, we'll want to compare samples at equal sampling depth. We use the rarefaction plot to find a downsampling depth where we see as much diversity as possible, while keeping as many samples as possible. \n",
    "\n",
    "Since this function calculates alpha diversity metrics repeatedly at different sampling depths, its a little slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44174333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.diversity.actions as diversity_actions\n",
    "\n",
    "alpha_rarefaction_viz, = diversity_actions.alpha_rarefaction(\n",
    "    table=table,\n",
    "    phylogeny=rooted_tree,\n",
    "    max_depth=4000,\n",
    "    metadata=sample_metadata_md,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ceb108",
   "metadata": {},
   "source": [
    "Save and view at view.qiime2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_rarefaction_viz.save('alpha_rarefaction_viz.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f926e",
   "metadata": {},
   "source": [
    "I think downsampling to 1103 should be ok! Alpha diversity seems to plateau and we only lose 3 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685b7b5",
   "metadata": {},
   "source": [
    "### *Question: Which body sites host the most and least diverse microbiota?*\n",
    "\n",
    "*Answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90239f3b",
   "metadata": {},
   "source": [
    "**Step 2: calculate all diversity metrics on the downsampled dataset**\n",
    "- again, qiime2 wraps it all in one command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_results = diversity_actions.core_metrics_phylogenetic(\n",
    "    phylogeny=rooted_tree,\n",
    "    table=table,\n",
    "    sampling_depth=1103,\n",
    "    metadata=sample_metadata_md,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5548c87",
   "metadata": {},
   "source": [
    "**Step 3: extract the metrics that we're interested in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd19ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the downsampled dataset\n",
    "rarefied_table = action_results.rarefied_table\n",
    "# shannon diversity (alpha diversity)\n",
    "shannon_vector = action_results.shannon_vector\n",
    "# weighted unifrac (beta diversity)\n",
    "weighted_unifrac_distance_matrix = action_results.weighted_unifrac_distance_matrix\n",
    "# the weighted and unweightedunifrac pcoa plots\n",
    "unweighted_unifrac_emperor_viz = action_results.unweighted_unifrac_emperor\n",
    "weighted_unifrac_emperor_viz = action_results.weighted_unifrac_emperor\n",
    "unweighted_unifrac_emperor_viz.save('unweighted_unifrac_emperor_viz.qzv')\n",
    "weighted_unifrac_emperor_viz.save('weighted_unifrac_emperor_viz.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc3726",
   "metadata": {},
   "source": [
    "**Step 4: test for associations with metadata**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513c3df",
   "metadata": {},
   "source": [
    "looks like shannon diversity actually *increased* after antibiotic usage. Pretty cool!\n",
    "- since each sample has a single number for shannon diversity, we're using a Kruskal-Wallis test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32a023",
   "metadata": {},
   "outputs": [],
   "source": [
    "shannon_group_significance_viz, = diversity_actions.alpha_group_significance(\n",
    "    alpha_diversity=shannon_vector,\n",
    "    metadata=sample_metadata_md,\n",
    ")\n",
    "shannon_group_significance_viz.save('shannon_significance.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52800ad",
   "metadata": {},
   "source": [
    "beta diversity appears to be associated with body site. It makes sense that different bugs would live in different places\n",
    "- since beta diversity creates a distance matrix, we're using a PERMANOVA\n",
    "- take a look at the beta diversity pcoa plots (emperor_viz) at view.qiime2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_site_mdc = sample_metadata_md.get_column('body-site')\n",
    "weighted_unifrac_body_site_group_significance_viz, = diversity_actions.beta_group_significance(\n",
    "    distance_matrix=weighted_unifrac_distance_matrix,\n",
    "    metadata=body_site_mdc,\n",
    "    pairwise=True,\n",
    ")\n",
    "subject_mdc = sample_metadata_md.get_column('subject')\n",
    "weighted_unifrac_subject_group_significance_viz, = diversity_actions.beta_group_significance(\n",
    "    distance_matrix=weighted_unifrac_distance_matrix,\n",
    "    metadata=subject_mdc,\n",
    "    pairwise=True,\n",
    ")\n",
    "weighted_unifrac_body_site_group_significance_viz.save('body_site.permanova.qzv')\n",
    "weighted_unifrac_subject_group_significance_viz.save('subject.permanova.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fabd51",
   "metadata": {},
   "source": [
    "## 5) Differential abundance testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797ff1c",
   "metadata": {},
   "source": [
    "QIIME2 has support for ANCOM, so we're going to use ANCOM. If you're savvy, you can export your feature table to .tsv and use any method you want though. \n",
    "\n",
    "\n",
    "As written, this code tests for the effect of antibiotics on the gut microbiome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34d316d",
   "metadata": {},
   "source": [
    "**Step 1: create a filtered table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4b3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.feature_table.actions as feature_table_actions\n",
    "\n",
    "gut_table, = feature_table_actions.filter_samples(\n",
    "    table=table,\n",
    "    metadata=sample_metadata_md,\n",
    "    where='[body-site]=\"gut\"',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762ba7c",
   "metadata": {},
   "source": [
    "**Step 2: test for differential abundance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c51076",
   "metadata": {},
   "source": [
    "First, run on the ASV level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f22443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2.plugins.composition.actions as composition_actions\n",
    "## run ancom (formula='reported_antibiotic_usage' tells it to compare microbes between antibiotic and non-antibiotic samples)\n",
    "ancombc_abx, = composition_actions.ancombc(\n",
    "    table=gut_table,\n",
    "    metadata=sample_metadata_md,\n",
    "    formula='reported_antibiotic_usage',\n",
    ")\n",
    "## create a barplot of significant features\n",
    "da_barplot_abx_viz, = composition_actions.da_barplot(\n",
    "    data=ancombc_abx,\n",
    "    significance_threshold=0.1,\n",
    ")\n",
    "\n",
    "da_barplot_abx_viz.save('ancom.asv.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c910f34",
   "metadata": {},
   "source": [
    "Attach a taxonomy to the top ASV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c56c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the ancom results\n",
    "da_barplot_abx_viz.export_data('ancombc_export')\n",
    "# read in the p values and log fold changes\n",
    "ancom_results = pd.read_csv('ancombc_export/q_val_slice.csv', sep=',', index_col=0)[['reported_antibiotic_usageYes'\\\n",
    "                ]].rename(columns={'reported_antibiotic_usageYes':'qval'}).join(pd.read_csv('ancombc_export/lfc_slice.csv', sep=',',\n",
    "                     index_col=0)[['reported_antibiotic_usageYes'\\\n",
    "                ]].rename(columns={'reported_antibiotic_usageYes':'LFC'})).sort_values(by = 'qval').join(taxonomy_as_md_md.to_dataframe())\n",
    "# print the most significant ASV\n",
    "print(ancom_results.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b5ef0",
   "metadata": {},
   "source": [
    "**Step 3: try again at higher taxonomic levels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a genus-level feature table\n",
    "gut_table_l6, = taxa_actions.collapse(\n",
    "    table=gut_table,\n",
    "    taxonomy=taxonomy,\n",
    "    level=6,\n",
    ")\n",
    "## run ancom\n",
    "ancombc_abx_l6, = composition_actions.ancombc(\n",
    "    table=gut_table_l6,\n",
    "    metadata=sample_metadata_md,\n",
    "    formula='reported_antibiotic_usage',\n",
    ")\n",
    "## plot\n",
    "da_barplot_abx_l6_viz, = composition_actions.da_barplot(\n",
    "    data=ancombc_abx_l6,\n",
    "    significance_threshold=0.1,\n",
    ")\n",
    "da_barplot_abx_l6_viz.save('ancom.l6.qzv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8a4f9",
   "metadata": {},
   "source": [
    "### *Question: Run ANCOM again at the class level (level 3). Are there any differentially abundant taxa?*\n",
    "\n",
    "*Answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a genus-level feature table\n",
    "gut_table_l6, = taxa_actions.collapse(\n",
    "    table=gut_table,\n",
    "    taxonomy=taxonomy,\n",
    "    level=3,\n",
    ")\n",
    "## run ancom\n",
    "ancombc_abx_l6, = composition_actions.ancombc(\n",
    "    table=gut_table_l6,\n",
    "    metadata=sample_metadata_md,\n",
    "    formula='reported_antibiotic_usage',\n",
    ")\n",
    "## plot\n",
    "da_barplot_abx_l6_viz, = composition_actions.da_barplot(\n",
    "    data=ancombc_abx_l6,\n",
    "    significance_threshold=0.1,\n",
    ")\n",
    "da_barplot_abx_l6_viz.save('ancom.l6.qzv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-amplicon-2024.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
